# ðŸ¦Š AMLynx

> **AMLynx** is an advanced **Anti-Money Laundering (AML) intelligence framework** for detecting suspicious financial activities using a **hybrid approach** that blends **rule-based systems** with **machine-learning anomaly detection**.

[![License: MIT](https://img.shields.io/badge/License-MIT-black.svg)](#license)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](#requirements)
[![FastAPI](https://img.shields.io/badge/API-FastAPI-009688.svg)](#api)
[![Build](https://img.shields.io/badge/Build-Passing-brightgreen.svg)]()
[![Docker](https://img.shields.io/badge/Docker-ready-2496ED.svg)]()

---

## ðŸ“˜ Table of Contents

* [Overview](#overview)
* [Key Features](#key-features)
* [Architecture](#architecture)
* [Folder Structure](#folder-structure)
* [Quick Start (Docker)](#quick-start-docker)
* [Development Setup](#development-setup)
* [Configuration](#configuration)
* [Data Pipeline](#data-pipeline)
* [Rule Engine](#rule-engine)
* [Anomaly Detection](#anomaly-detection)
* [Hybrid Scoring](#hybrid-scoring)
* [API](#api)
* [Logging & Monitoring](#logging--monitoring)
* [Testing](#testing)
* [Roadmap](#roadmap)
* [Contributing](#contributing)
* [License](#license)

---

## ðŸ§  Overview

**AMLynx** provides a modular, production-ready foundation for **automated AML screening** in financial systems.
It unifies:

* **Business rules** (expert knowledge)
* **Anomaly detection models** (data-driven insight)
* **Hybrid scoring** for explainable and tunable alerts

Built with **FastAPI**, **SQLAlchemy**, and **modern ML libraries**, AMLynx is designed for **banks, fintechs, and regulators** who need transparency, extensibility, and auditability in their AML workflows.

---

## âœ¨ Key Features

âœ… **Modular Architecture** â€“ Independent, pluggable modules for rules, models, features, and scoring
âœ… **Hybrid Risk Scoring** â€“ Combine ML anomaly scores and rule-based logic
âœ… **FastAPI REST Interface** â€“ Production-ready API with OpenAPI documentation
âœ… **Pydantic Schemas** â€“ Type-safe validation for all inputs/outputs
âœ… **Batch & Streaming ETL** â€“ Supports both batch ingestion and near-real-time pipelines
âœ… **SQLAlchemy ORM** â€“ Database-agnostic (PostgreSQL, SQLite, etc.)
âœ… **Unified Logging** â€“ Centralized JSON logging for analytics and compliance
âœ… **Containerized Deployment** â€“ Ship and scale with Docker Compose or Kubernetes
âœ… **Extensible** â€“ Add new anomaly models, rules, or scoring logic with minimal coupling

---

## ðŸ§© Architecture

AMLynx follows a **layered architecture**:

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚         API Layer           â”‚
                â”‚ (FastAPI REST + Schemas)    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚       Pipeline Layer      â”‚
                 â”‚ (ETL â†’ Features â†’ Rules â†’ â”‚
                 â”‚  Anomaly â†’ Hybrid Scoring)â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚        Data Layer         â”‚
                 â”‚ (DB Models + Storage)     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Common & Core Utilities â”‚
                 â”‚ (Config, Logging, Helpers)â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Folder Structure

| Directory         | Description                                                                 |
| ----------------- | --------------------------------------------------------------------------- |
| **aml/**          | Core AML intelligence logic â€” primary anomaly model(s) and risk aggregation |
| **anomaly/**      | Low-level detectors (Isolation Forest, LOF, etc.) and explainers            |
| **api/**          | FastAPI app exposing endpoints for scoring, transactions, and health checks |
| **common/**       | Logging setup, configuration management, and shared utilities               |
| **data/**         | ETL batch scripts for data cleaning, transformation, and ingestion          |
| **db/**           | SQLAlchemy ORM models and session management                                |
| **features/**     | Feature extraction and feature-store logic                                  |
| **pipeline/**     | Orchestrates end-to-end scoring workflow                                    |
| **rules_engine/** | Business rule registration and evaluation engine                            |
| **schemas/**      | Pydantic models for input/output validation                                 |
| **scoring/**      | Hybrid logic combining rule and anomaly scores                              |

---

## âš¡ Quick Start (Docker)

```bash
git clone https://github.com/benefoon/AMLynx.git
cd AMLynx

# 1ï¸âƒ£ Configure environment
cp .env.example .env

# 2ï¸âƒ£ Launch services
docker compose up --build

# 3ï¸âƒ£ (Optional) Seed demo data
docker compose exec api python scripts/seed_data.py

# 4ï¸âƒ£ Access API docs
http://localhost:8000/docs
```

---

## ðŸ’» Development Setup

### Requirements

* Python 3.10+
* FastAPI, SQLAlchemy, scikit-learn, pandas
* Docker (optional for deployment)

### Local Setup

```bash
python -m venv .venv
source .venv/bin/activate
pip install -e ".[dev]"
uvicorn src.api.app:app --reload --port 8000
```

Run tests:

```bash
pytest -q
```

---

## âš™ï¸ Configuration

Defined in `.env` or system environment variables.
Common entries:

```ini
DATABASE_URL=postgresql+psycopg2://user:pass@localhost:5432/amlynx
MODEL_PATH=./models/isolation_forest.pkl
ENABLE_RULES=true
ENABLE_GRPC=false
API_PORT=8000
LOG_LEVEL=INFO
```

---

## ðŸ§¬ Data Pipeline

1. **ETL Stage** (`data/etl_batch.py`)

   * Cleans and normalizes incoming transaction data.
   * Handles missing fields, currency conversion, and schema validation.

2. **Feature Extraction** (`features/store.py`)

   * Generates statistical or behavioral features (velocity, frequency, deviation).
   * Maintains feature cache for repeated scoring.

3. **Rule Evaluation** (`rules_engine/engine.py`)

   * Evaluates deterministic business rules.

4. **Anomaly Detection** (`aml/anomaly.py`, `anomaly/detector.py`)

   * Runs machine-learning models on feature vectors.

5. **Hybrid Scoring** (`scoring/hybrid.py`)

   * Combines ML and rule outputs into unified risk score.

---

## ðŸ§¾ Rule Engine

Rules are defined in JSON/YAML or Python DSL format and evaluated in `rules_engine/engine.py`.

Example:

```yaml
id: R001
name: High-Value Offshore
condition: transaction.amount_usd > 10000 and transaction.country in ["KY", "PA", "VG"]
action:
  score: +50
  reason: "Large transaction to offshore jurisdiction"
```

Each rule returns:

```json
{
  "rule_id": "R001",
  "triggered": true,
  "score": 50,
  "reason": "Large transaction to offshore jurisdiction"
}
```

---

## ðŸ¤– Anomaly Detection

Defined in:

* `aml/anomaly.py`
* `anomaly/detector.py`

Supports:

* **Isolation Forest**
* **Local Outlier Factor**
* **Autoencoder (planned)**

Each detector exposes:

```python
predict(X) -> np.ndarray
score(X) -> List[float]
explain(X) -> Dict[str, float]
```

Example usage:

```python
from aml.anomaly import AnomalyModel
model = AnomalyModel.load("models/isolation_forest.pkl")
scores = model.score(batch_features)
```

---

## âš–ï¸ Hybrid Scoring

Combines rule-based and model-based results:

```python
final_score = 0.6 * anomaly_score + 0.4 * rule_score
alert = final_score > threshold
```

Configurable weights are set in `.env` or `common/config.py`.
Returns risk levels (Low / Medium / High) with explainability.

---

